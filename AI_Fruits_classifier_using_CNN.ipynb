{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem statement\n",
    "\n",
    "\n",
    "- Build a CNN Based multi classifier to detect which type of fruits it is?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "##Import libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialising the CNN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\SHASHANK\\Anaconda3\\envs\\TensorFolw\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\SHASHANK\\Anaconda3\\envs\\TensorFolw\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Convolution(64 feature detector of dimension 3 by 3), input shape 3 layer for color image)\n",
    "classifier.add(Conv2D(64,(3,3),input_shape = (64,64,3), activation = 'relu'))\n",
    "## MaxPooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "## Add another layer\n",
    "classifier.add(Conv2D(64,(3,3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "## Add another layer\n",
    "classifier.add(Conv2D(64,(3,3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Flattening\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fully connected ANN, Hidden ANN and output layer\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output layer\n",
    "classifier.add(Dense(units = 18, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compliling\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 29, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               295040    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 18)                2322      \n",
      "=================================================================\n",
      "Total params: 373,010\n",
      "Trainable params: 373,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##Model summary\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data importing and transforming and scaling\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scaling test data\n",
    "##no  data augmentation\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9310 images belonging to 18 classes.\n"
     ]
    }
   ],
   "source": [
    "## Importing training data\n",
    "train_set = train_datagen.flow_from_directory('C:\\\\Users\\\\SHASHANK\\\\Desktop\\\\AI_Fruits_classifer\\\\Fruit\\\\training',\n",
    "                                               target_size=(64, 64),\n",
    "                                               \n",
    "                                               class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Apple Braeburn': 0,\n",
       " 'Apple Golden 1': 1,\n",
       " 'Apple Golden 2': 2,\n",
       " 'Apple Golden 3': 3,\n",
       " 'Apple Granny Smith': 4,\n",
       " 'Apple Red 1': 5,\n",
       " 'Apple Red 2': 6,\n",
       " 'Apple Red 3': 7,\n",
       " 'Apple Red Delicious': 8,\n",
       " 'Apple Red Yellow': 9,\n",
       " 'Banana': 10,\n",
       " 'Banana Red': 11,\n",
       " 'Tomato 1': 12,\n",
       " 'Tomato 2': 13,\n",
       " 'Tomato 3': 14,\n",
       " 'Tomato 4': 15,\n",
       " 'Tomato Cherry Red': 16,\n",
       " 'Tomato Maroon': 17}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Apple Braeburn': 0, 'Apple Golden 1': 1, 'Apple Golden 2': 2, 'Apple Golden 3': 3, 'Apple Granny Smith': 4, 'Apple Red 1': 5, 'Apple Red 2': 6, 'Apple Red 3': 7, 'Apple Red Delicious': 8, 'Apple Red Yellow': 9, 'Banana': 10, 'Banana Red': 11, 'Tomato 1': 12, 'Tomato 2': 13, 'Tomato 3': 14, 'Tomato 4': 15, 'Tomato Cherry Red': 16, 'Tomato Maroon': 17}\n"
     ]
    }
   ],
   "source": [
    "#which is differnt types of class?\n",
    "label_map = (train_set.class_indices)\n",
    "print(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3119 images belonging to 18 classes.\n"
     ]
    }
   ],
   "source": [
    "## Importng test data\n",
    "test_set = test_datagen.flow_from_directory('C:\\\\Users\\\\SHASHANK\\\\Desktop\\\\AI_Fruits_classifer\\\\Fruit\\\\test',\n",
    "                                            target_size=(64, 64),\n",
    "                                            \n",
    "                                            class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\SHASHANK\\Anaconda3\\envs\\TensorFolw\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\SHASHANK\\Anaconda3\\envs\\TensorFolw\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/2\n",
      "291/291 [==============================] - 219s 753ms/step - loss: 0.0765 - accuracy: 0.9719 - val_loss: 0.0135 - val_accuracy: 0.9858\n",
      "Epoch 2/2\n",
      "291/291 [==============================] - 218s 750ms/step - loss: 0.0177 - accuracy: 0.9931 - val_loss: 0.0222 - val_accuracy: 0.9911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1f557f8d848>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## fitting model to images\n",
    "classifier.fit_generator(\n",
    "        train_set,\n",
    "        epochs=2,\n",
    "        validation_data=test_set\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here we can see that we are getting 99.31% accuray on the training dataset and 99.11% accuracy on the testing dataset. which is very nice accuary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prediction of single new data\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image= image.load_img('C:\\\\Users\\\\SHASHANK\\\\Desktop\\\\AI_Fruits_classifer\\\\Fruit\\\\inference\\\\apple.jpg'\n",
    "                           ,target_size =(64,64))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x1F5601172C8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert image to array\n",
    "test_image_arr = image.img_to_array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[248., 255., 248.],\n",
       "        [253., 255., 252.],\n",
       "        [253., 255., 252.],\n",
       "        ...,\n",
       "        [255., 254., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.]],\n",
       "\n",
       "       [[255., 255., 253.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 253., 254.],\n",
       "        ...,\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.]],\n",
       "\n",
       "       [[255., 253., 254.],\n",
       "        [255., 253., 254.],\n",
       "        [255., 253., 254.],\n",
       "        ...,\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        ...,\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.]],\n",
       "\n",
       "       [[255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        ...,\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.]],\n",
       "\n",
       "       [[255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        ...,\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.]]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For single prediction change the dimension . \n",
    "\n",
    "test_image=test_image_arr.reshape(1,64,64,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = classifier.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 1.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 7.720564e-38, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=result.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Apple Braeburn': 0, 'Apple Golden 1': 1, 'Apple Golden 2': 2, 'Apple Golden 3': 3, 'Apple Granny Smith': 4, 'Apple Red 1': 5, 'Apple Red 2': 6, 'Apple Red 3': 7, 'Apple Red Delicious': 8, 'Apple Red Yellow': 9, 'Banana': 10, 'Banana Red': 11, 'Tomato 1': 12, 'Tomato 2': 13, 'Tomato 3': 14, 'Tomato 4': 15, 'Tomato Cherry Red': 16, 'Tomato Maroon': 17}\n"
     ]
    }
   ],
   "source": [
    "print(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## print label\n",
    "\n",
    "if result == 0.0:\n",
    "    prediction = 'Apple Braeburn'\n",
    "elif result == 1:\n",
    "    prediction = 'Apple Golden 1'\n",
    "elif result == 2:\n",
    "    prediction = \"Apple Golden 2\"\n",
    "elif result == 3:\n",
    "    prediction = \"Apple Golden 3\"\n",
    "elif result == 4:\n",
    "    prediction = \"Apple Granny Smith\"\n",
    "elif result == 5:\n",
    "    prediction = \"Apple Red 1\"\n",
    "elif result == 6:\n",
    "    prediction = \"Apple Red 2\"\n",
    "elif result == 7:\n",
    "    prediction = \"Apple Red 3\"\n",
    "elif result == 8:\n",
    "    prediction = \"Apple Red Delicious\"\n",
    "elif result == 9:\n",
    "    prediction = \"Apple Red Yellow\"\n",
    "elif result == 10:\n",
    "    prediction = \"Banana\"\n",
    "elif result == 11:\n",
    "    prediction = \"Banana Red\"\n",
    "elif result == 12:\n",
    "    prediction = \"Tomato 1\"\n",
    "elif result == 13:\n",
    "    prediction = \"Tomato 2\"\n",
    "elif result == 14:\n",
    "    prediction = \"Tomato 3\"\n",
    "elif result == 15:\n",
    "    prediction = \"Tomato 4\"\n",
    "elif result == 16:\n",
    "    prediction = \"Tomato Cherry Red\"\n",
    "else:\n",
    "    prediction = 'Tomato Maroon'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apple Red 2'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
